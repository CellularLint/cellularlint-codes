{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dbbf630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from collections.abc import Iterable\n",
    "from torchtext import data\n",
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "from transformers.optimization import *\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0960de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7060b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset into dataframes\n",
    "ROOT_PATH = \"/home/rahman75/Research/Project_Conflict/Data/SNLI/\"\n",
    "LOADING_PATH = os.path.join(ROOT_PATH, \"snli_raw\")\n",
    "SAVING_PATH = os.path.join(ROOT_PATH,\"snli_processed\")\n",
    "df_train = pd.read_csv(os.path.join(LOADING_PATH, \"snli_1.0_train.txt\"), sep=\"\\t\")\n",
    "df_dev = pd.read_csv(os.path.join(LOADING_PATH, \"snli_1.0_dev.txt\"), sep=\"\\t\")\n",
    "df_test = pd.read_csv(os.path.join(LOADING_PATH, \"snli_1.0_test.txt\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d145e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the required columns form the dataset\n",
    "df_train = df_train[['gold_label','sentence1','sentence2']]\n",
    "df_dev = df_dev[['gold_label','sentence1','sentence2']]\n",
    "df_test = df_test[['gold_label','sentence1','sentence2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70df1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contradiction</th>\n",
       "      <td>183187</td>\n",
       "      <td>183185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entailment</th>\n",
       "      <td>183416</td>\n",
       "      <td>183414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>182764</td>\n",
       "      <td>182762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sentence1  sentence2\n",
       "gold_label                         \n",
       "-                    785        785\n",
       "contradiction     183187     183185\n",
       "entailment        183416     183414\n",
       "neutral           182764     182762"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n",
    "# Analyzing the data\n",
    "df_train.groupby('gold_label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2666765b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contradiction</th>\n",
       "      <td>3278</td>\n",
       "      <td>3278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entailment</th>\n",
       "      <td>3329</td>\n",
       "      <td>3329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>3235</td>\n",
       "      <td>3235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sentence1  sentence2\n",
       "gold_label                         \n",
       "-                    158        158\n",
       "contradiction       3278       3278\n",
       "entailment          3329       3329\n",
       "neutral             3235       3235"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()\n",
    "# Analyzing the data\n",
    "df_dev.groupby('gold_label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfae9345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contradiction</th>\n",
       "      <td>3237</td>\n",
       "      <td>3237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entailment</th>\n",
       "      <td>3368</td>\n",
       "      <td>3368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>3219</td>\n",
       "      <td>3219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sentence1  sentence2\n",
       "gold_label                         \n",
       "-                    176        176\n",
       "contradiction       3237       3237\n",
       "entailment          3368       3368\n",
       "neutral             3219       3219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()\n",
    "# Analyzing the data\n",
    "df_test.groupby('gold_label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca7e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the entries from all train, dev and test datasets with label '-'\n",
    "df_train = df_train[df_train['gold_label'] != '-']\n",
    "df_dev = df_dev[df_dev['gold_label'] != '-']\n",
    "df_test = df_test[df_test['gold_label'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508fdbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contradiction</th>\n",
       "      <td>183185</td>\n",
       "      <td>183185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entailment</th>\n",
       "      <td>183414</td>\n",
       "      <td>183414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>182762</td>\n",
       "      <td>182762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sentence1  sentence2\n",
       "gold_label                         \n",
       "contradiction     183185     183185\n",
       "entailment        183414     183414\n",
       "neutral           182762     182762"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the rows from the data with NaN values\n",
    "df_train = df_train.dropna(subset = ['sentence2'])\n",
    "df_train.groupby('gold_label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e12801f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the same tokenizer used in pre-training\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7be5feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the tokens from BertTokenizer\n",
    "sep_token = tokenizer.sep_token\n",
    "cls_token = tokenizer.cls_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "#using the token ids\n",
    "sep_token_idx = tokenizer.sep_token_id\n",
    "cls_token_idx = tokenizer.cls_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294cc93",
   "metadata": {},
   "source": [
    "<p>Let's have some improvement here<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bc64c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the maximum length of the sequence\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "# defining the maximum length of each sentence\n",
    "max_sentence_length = 200\n",
    "max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d25dab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to tokenize the sentences using BertTokenizer\n",
    "def tokenize_sentences(sentence):\n",
    "  tokens = tokenizer.tokenize(sentence)\n",
    "  return tokens\n",
    "# function to reduce the size of the sentence to the max_input_length\n",
    "def reduce_sentence_length(sentence):\n",
    "  tokens = sentence.strip().split(\" \")\n",
    "  tokens = tokens[:max_input_length]\n",
    "  return tokens\n",
    "# function to trim the sentence to the max_sentence_length\n",
    "def trim_sentence(sentence):\n",
    "  # splitting the sentence\n",
    "  sentence = sentence.split()\n",
    "  # check if the sentence has 128 or more tokens\n",
    "  if len(sentence) >= 200:\n",
    "    sentence = sentence[:max_sentence_length]\n",
    "  return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c43f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimming the sentences upto the maximum length\n",
    "df_train['sentence1'] = df_train['sentence1'].apply(trim_sentence)\n",
    "df_dev['sentence1'] = df_dev['sentence1'].apply(trim_sentence)\n",
    "df_test['sentence1'] = df_test['sentence1'].apply(trim_sentence)\n",
    "df_train['sentence2'] = df_train['sentence2'].apply(trim_sentence)\n",
    "df_dev['sentence2'] = df_dev['sentence2'].apply(trim_sentence)\n",
    "df_test['sentence2'] = df_test['sentence2'].apply(trim_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a066a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the [cls] and [sep] tokens\n",
    "df_train['t_sentence1'] = cls_token + ' ' + df_train['sentence1'] + ' ' + sep_token + ' '\n",
    "df_dev['t_sentence1'] = cls_token + ' ' + df_dev['sentence1'] + ' ' + sep_token + ' '\n",
    "df_test['t_sentence1'] = cls_token + ' ' + df_test['sentence1'] + ' ' + sep_token + ' '\n",
    "df_train['t_sentence2'] = df_train['sentence2'] + ' ' + sep_token\n",
    "df_dev['t_sentence2'] = df_dev['sentence2'] + ' ' + sep_token\n",
    "df_test['t_sentence2'] = df_test['sentence2'] + ' ' + sep_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd23a55",
   "metadata": {},
   "source": [
    "Dont Run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14027f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the [cls] and [sep] tokens\n",
    "df_train['t_sentence1'] = df_train['sentence1'] \n",
    "df_dev['t_sentence1'] =  df_dev['sentence1']\n",
    "df_test['t_sentence1'] = df_test['sentence1'] \n",
    "df_train['t_sentence2'] = df_train['sentence2'] \n",
    "df_dev['t_sentence2'] = df_dev['sentence2']\n",
    "df_test['t_sentence2'] = df_test['sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8262bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the BertTokenizer to the newly generated sentences\n",
    "df_train['b_sentence1'] = df_train['t_sentence1'].apply(tokenize_sentences)\n",
    "df_dev['b_sentence1'] = df_dev['t_sentence1'].apply(tokenize_sentences)\n",
    "df_test['b_sentence1'] = df_test['t_sentence1'].apply(tokenize_sentences)\n",
    "df_train['b_sentence2'] = df_train['t_sentence2'].apply(tokenize_sentences)\n",
    "df_dev['b_sentence2'] = df_dev['t_sentence2'].apply(tokenize_sentences)\n",
    "df_test['b_sentence2'] = df_test['t_sentence2'].apply(tokenize_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "769769e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the token type id's of the sentence-01\n",
    "def token_type_ids_sent_01(sentence):\n",
    "  try:\n",
    "    return [0] * len(sentence)\n",
    "  except:\n",
    "    return []\n",
    "# function to get the token type id's of the sentence-02\n",
    "def token_type_ids_sent_02(sentence):\n",
    "  try:\n",
    "    return [1] * len(sentence)\n",
    "  except:\n",
    "    return []\n",
    "\n",
    "\n",
    "# getting the token type ids for the sentences\n",
    "df_train['sentence1_token_type'] = df_train['b_sentence1'].apply(token_type_ids_sent_01)\n",
    "df_dev['sentence1_token_type'] = df_dev['b_sentence1'].apply(token_type_ids_sent_01)\n",
    "df_test['sentence1_token_type'] = df_test['b_sentence1'].apply(token_type_ids_sent_01)\n",
    "df_train['sentence2_token_type'] = df_train['b_sentence2'].apply(token_type_ids_sent_02)\n",
    "df_dev['sentence2_token_type'] = df_dev['b_sentence2'].apply(token_type_ids_sent_02)\n",
    "df_test['sentence2_token_type'] = df_test['b_sentence2'].apply(token_type_ids_sent_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3227f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the seqence from the tokenized sentences\n",
    "df_train['sequence'] = df_train['b_sentence1'] + df_train['b_sentence2']\n",
    "df_dev['sequence'] = df_dev['b_sentence1'] + df_dev['b_sentence2']\n",
    "df_test['sequence'] = df_test['b_sentence1'] + df_test['b_sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70530b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the attention mask of the given sentence\n",
    "def attention_mask_sentence(sentence):\n",
    "  try:\n",
    "    return [1] * len(sentence)\n",
    "  except:\n",
    "    return []\n",
    "\n",
    "# generating attention mask\n",
    "df_train['attention_mask'] = df_train['sequence'].apply(attention_mask_sentence)\n",
    "df_dev['attention_mask'] = df_dev['sequence'].apply(attention_mask_sentence)\n",
    "df_test['attention_mask'] = df_test['sequence'].apply(attention_mask_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6794e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the token type of both sentences\n",
    "df_train['token_type'] = df_train['sentence1_token_type'] + df_train['sentence2_token_type']\n",
    "df_dev['token_type'] = df_dev['sentence1_token_type'] + df_dev['sentence2_token_type']\n",
    "df_test['token_type'] = df_test['sentence1_token_type'] + df_test['sentence2_token_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "240401ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = df_dev.dropna(subset = ['sequence'])\n",
    "df_dev = df_dev.dropna(subset = ['token_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "508e3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert the attention_mask and token_type ids to int\n",
    "def convert_to_int(ids):\n",
    "  ids = [int(d) for d in ids]\n",
    "  return ids\n",
    "\n",
    "df_train['attention_mask'] = df_train['attention_mask'].apply(convert_to_int)\n",
    "df_dev['attention_mask'] = df_dev['attention_mask'].apply(convert_to_int)\n",
    "df_test['attention_mask'] = df_test['attention_mask'].apply(convert_to_int)\n",
    "df_train['token_type'] = df_train['token_type'].apply(convert_to_int)\n",
    "df_dev['token_type'] = df_dev['token_type'].apply(convert_to_int)\n",
    "df_test['token_type'] = df_test['token_type'].apply(convert_to_int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d98114c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to combine the sequences from lists\n",
    "def combine_sequence(sequence):\n",
    "  return \" \".join(sequence)\n",
    "# function to combine the masks\n",
    "def combine_mask(mask):\n",
    "  mask = [str(m) for m in mask]\n",
    "  return \" \".join(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "980aa1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the inputs to sequential for torchtext Field\n",
    "df_train['sequence'] = df_train['sequence'].apply(combine_sequence)\n",
    "df_dev['sequence']  = df_dev['sequence'].apply(combine_sequence)\n",
    "df_test['sequence'] = df_test['sequence'].apply(combine_sequence)\n",
    "df_train['attention_mask'] = df_train['attention_mask'].apply(combine_mask)\n",
    "df_dev['attention_mask'] = df_dev['attention_mask'].apply(combine_mask)\n",
    "df_test['attention_mask'] = df_test['attention_mask'].apply(combine_mask)\n",
    "df_train['token_type'] = df_train['token_type'].apply(combine_mask)\n",
    "df_dev['token_type'] = df_dev['token_type'].apply(combine_mask)\n",
    "df_test['token_type'] = df_test['token_type'].apply(combine_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1455d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['token_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65ebc87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the required columns\n",
    "df_train = df_train[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
    "df_dev = df_dev[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
    "df_test = df_test[['gold_label', 'sequence', 'attention_mask', 'token_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text field for sequence\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                 use_vocab = False,\n",
    "                 tokenize = reduce_sentence_length,\n",
    "                 preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                 pad_token = pad_token_idx,\n",
    "                 unk_token = unk_token_idx)\n",
    "# label field for label\n",
    "LABEL = data.LabelField()\n",
    "# text field for attention mask\n",
    "ATTENTION = data.Field(batch_first = True,\n",
    "                      use_vocab = False,\n",
    "                      tokenize = reduce_sentence_length,\n",
    "                      preprocessing = convert_to_int,\n",
    "                      pad_token = pad_token_idx)\n",
    "# text field for token type ids\n",
    "TTYPE = data.Field(batch_first = True, \n",
    "                  use_vocab = False,\n",
    "                  tokenize = reduce_sentence_length,\n",
    "                  preprocessing = convert_to_int,\n",
    "                  pad_token = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d34af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('label', LABEL), ('sequence', TEXT), ('attention_mask', ATTENTION), ('token_type', TTYPE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ea4bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data in the files\n",
    "\n",
    "df_train.to_csv(os.path.join(SAVING_PATH,'snli_1.0_train_smpl.csv'), index=False)\n",
    "df_dev.to_csv(os.path.join(SAVING_PATH,'snli_1.0_dev_smpl.csv'), index=False)\n",
    "df_test.to_csv(os.path.join(SAVING_PATH,'snli_1.0_test_smpl.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81268cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                    path = os.path.join(ROOT_PATH,'snli_processed'),\n",
    "                                    train = 'snli_1.0_train.csv',\n",
    "                                    validation = 'snli_1.0_dev.csv',\n",
    "                                    test = 'snli_1.0_test.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = fields,\n",
    "                                    skip_header = True)\n",
    "train_data_len = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the vocabulary for labels\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bucketiterator for preparing batches for training\n",
    "BATCH_SIZE = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "                               (train_data, valid_data, test_data),\n",
    "                               batch_size = BATCH_SIZE,\n",
    "                               sort_key = lambda x: len(x.sequence),\n",
    "                               sort_within_batch = False,\n",
    "                               device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c21a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "class BERTNLIModel(nn.Module):\n",
    "  def __init__(self, bert_model, hidden_dim, output_dim,):\n",
    "    super().__init__()\n",
    "    self.bert = bert_model\n",
    "    embedding_dim = bert_model.config.to_dict()['hidden_size']\n",
    "    self.out = nn.Linear(embedding_dim, output_dim)\n",
    "  def forward(self, sequence, attn_mask, token_type):\n",
    "    embedded = self.bert(input_ids = sequence, attention_mask =  \n",
    "                      attn_mask, token_type_ids = token_type)[1]\n",
    "    output = self.out(embedded)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83452c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "HIDDEN_DIM = 512\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "model = BERTNLIModel(bert_model, HIDDEN_DIM, OUTPUT_DIM,).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d33db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-6, correct_bias=False)\n",
    "def get_scheduler(optimizer, warmup_steps):\n",
    "  scheduler = get_constant_schedule_with_warmup(optimizer,\n",
    "                                      num_warmup_steps=warmup_steps)\n",
    "  return scheduler\n",
    "# using the cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "fp16 = False\n",
    "#if fp16:\n",
    "#   try:\n",
    "#     from apex import amp\n",
    "#   except ImportError:\n",
    "#     raise ImportError(\"Please install apex from\n",
    "#           https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "#model, optimizer = amp.initialize(model, optimizer, opt_level='O1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ca3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the accuracy of model\n",
    "def accuracy(pred, y):\n",
    "  max_preds = pred.argmax(dim = 1, keepdim = True)\n",
    "  correct = (max_preds.squeeze(1)==y).float()\n",
    "  return correct.sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d757fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_grad_norm = 1\n",
    "def train(model, iterator, optimizer, criterion, scheduler):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  model.train()\n",
    "  for batch in iterator:\n",
    "    optimizer.zero_grad() # clear gradients first\n",
    "    torch.cuda.empty_cache() # releases all unoccupied cached memory\n",
    "    sequence = batch.sequence\n",
    "    attn_mask = batch.attention_mask\n",
    "    token_type = batch.token_type\n",
    "    label = batch.label\n",
    "    predictions = model(sequence, attn_mask, token_type)\n",
    "    loss = criterion(predictions, label)\n",
    "    acc = accuracy(predictions, label)\n",
    "    if fp16:\n",
    "      with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        scaled_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer),\n",
    "                                       max_grad_norm)\n",
    "    else:\n",
    "      loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aea695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for batch in iterator:\n",
    "      sequence = batch.sequence\n",
    "      attn_mask = batch.attention_mask\n",
    "      token_type = batch.token_type\n",
    "      labels = batch.label\n",
    "      predictions = model(sequence, attn_mask, token_type)\n",
    "      loss = criterion(predictions, labels)\n",
    "      acc = accuracy(predictions, labels)\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1\n",
    "warmup_percent = 0.2\n",
    "total_steps = math.ceil(N_EPOCHS * train_data_len * 1./BATCH_SIZE)\n",
    "warmup_steps = int(total_steps*warmup_percent)\n",
    "scheduler = get_scheduler(optimizer, warmup_steps)\n",
    "best_valid_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "  train_loss, train_acc = train(model, train_iterator, optimizer, \n",
    "                               criterion, scheduler)\n",
    "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "  if valid_loss < best_valid_loss:\n",
    "    best_valid_loss = valid_loss\n",
    "    torch.save(model.state_dict(), os.path.join(ROOT_PATH, 'saved_models/bert-nli.pt'))\n",
    "   \n",
    "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.tensor([0.12, 0.32]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cab70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
